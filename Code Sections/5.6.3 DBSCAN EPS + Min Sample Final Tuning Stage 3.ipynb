{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadbadi/Clustering_FE_MCA/blob/main/Code%20Sections/5.6.3%20DBSCAN%20EPS%20%2B%20Min%20Sample%20Final%20Tuning%20Stage%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.6.3 DBSCAN EPS + Min Sample Tuning: Stage 3 - Final Tuning**\n",
        "### **Narrowest jumps of eps and min sample based on Stage 2 - APPROACH_1**"
      ],
      "metadata": {
        "id": "26iqgxvwZ544"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "n7Cv92pku7TN",
        "outputId": "7e272992-05e7-4df7-b06a-ea35968425c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All expected files found. Processing...\n",
            "Fine tuning: Set 2718 processed. Best: (eps: 1.5, min_samples: 13), Score: 0.1492\n",
            "Fine tuning: Set 2719 processed. Best: (eps: 1.5, min_samples: 13), Score: 0.1164\n",
            "Fine tuning: Set 2720 processed. Best: (eps: 1.6, min_samples: 8), Score: 0.1273\n",
            "Fine tuning: Set 2721 processed. Best: (eps: 1.6, min_samples: 8), Score: 0.1340\n",
            "Fine tuning: Set 2722 processed. Best: (eps: 1.6, min_samples: 3), Score: 0.1285\n",
            "Fine tuning: Set 2723 processed. Best: (eps: 2.0000000000000004, min_samples: 3), Score: 0.1734\n",
            "Fine tuning: Set 2724 processed. Best: (eps: 2.1000000000000005, min_samples: 7), Score: 0.1996\n",
            "Fine tuning: Set 2725 processed. Best: (eps: 2.1000000000000005, min_samples: 12), Score: 0.1974\n",
            "Fine tuning: Set 2726 processed. Best: (eps: 1.8000000000000003, min_samples: 3), Score: 0.3160\n",
            "Fine tuning: Set 2727 processed. Best: (eps: 2.400000000000001, min_samples: 3), Score: 0.2929\n",
            "Fine tuning: Set 2728 processed. Best: (eps: 2.1000000000000005, min_samples: 3), Score: 0.2930\n",
            "Fine tuning: Set 2729 processed. Best: (eps: 2.500000000000001, min_samples: 13), Score: 0.2952\n",
            "Fine tuning: Set 2730 processed. Best: (eps: 1.8000000000000003, min_samples: 3), Score: 0.3205\n",
            "Fine tuning: Set 2731 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2971\n",
            "Fine tuning: Set 2732 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2972\n",
            "Fine tuning: Set 2733 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2994\n",
            "Fine tuning: Set 2734 processed. Best: (eps: 1.4, min_samples: 16), Score: 0.1160\n",
            "Fine tuning: Set 2735 processed. Best: (eps: 2.1000000000000005, min_samples: 10), Score: 0.1988\n",
            "Fine tuning: Set 2736 processed. Best: (eps: 2.1000000000000005, min_samples: 8), Score: 0.2009\n",
            "Fine tuning: Set 2737 processed. Best: (eps: 2.0000000000000004, min_samples: 9), Score: 0.2141\n",
            "Fine tuning: Set 2738 processed. Best: (eps: 1.5, min_samples: 14), Score: 0.0990\n",
            "Fine tuning: Set 2739 processed. Best: (eps: 2.2000000000000006, min_samples: 13), Score: 0.1642\n",
            "Fine tuning: Set 2740 processed. Best: (eps: 2.1000000000000005, min_samples: 3), Score: 0.1736\n",
            "Fine tuning: Set 2741 processed. Best: (eps: 2.3000000000000007, min_samples: 17), Score: 0.1623\n",
            "Fine tuning: Set 2742 processed. Best: (eps: 1.8000000000000003, min_samples: 3), Score: 0.3015\n",
            "Fine tuning: Set 2743 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2815\n",
            "Fine tuning: Set 2744 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2817\n",
            "Fine tuning: Set 2745 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2838\n",
            "Fine tuning: Set 2746 processed. Best: (eps: 1.8000000000000003, min_samples: 3), Score: 0.3055\n",
            "Fine tuning: Set 2747 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2853\n",
            "Fine tuning: Set 2748 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2854\n",
            "Fine tuning: Set 2749 processed. Best: (eps: 2.5, min_samples: 3), Score: 0.2875\n",
            "\n",
            "Fine tuning for 'DBSCAN_Intermediate_Top10_chunk_20.csv' complete. Final best parameters saved to 'DBSCAN_Best_Fine_Params_chunk_20.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_992afacd-d9b1-4a8c-9815-bb5418ae6060\", \"DBSCAN_Best_Fine_Params_chunk_20.csv\", 5562)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import warnings\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import files\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/mohammadbadi/Clustering_FE_MCA/refs/heads/main/Output_CSV/FE_Encoded_New.csv\" # URL of the Dataset\n",
        "data = pd.read_csv(url)                                                           # Load the Dataset\n",
        "data = data.sample(frac=0.1, random_state=42)                                     # 10% Sample from Dataset\n",
        "\n",
        "                                                                                  # Set the range of chunks to process\n",
        "start_chunk = 20                                                                  # Edit this value for different Starting Number\n",
        "end_chunk = 20                                                                    # Edit this value according to number of chunks to be processed in 1 go\n",
        "\n",
        "expected_filenames = [f\"DBSCAN_Intermediate_Top10_chunk_{i}.csv\" for i in range(start_chunk, end_chunk + 1)]\n",
        "\n",
        "missing_files = [fname for fname in expected_filenames if not os.path.exists(fname)]  # Check for missing files in the Colab environment\n",
        "if missing_files:\n",
        "    print(f\"Error: The following expected files were not found: {missing_files}\")\n",
        "else:\n",
        "    print(\"All expected files found. Processing...\")\n",
        "\n",
        "for expected_filename in expected_filenames:\n",
        "    if not os.path.exists(expected_filename):\n",
        "        continue\n",
        "\n",
        "    intermediate_df = pd.read_csv(expected_filename)\n",
        "    final_results = []\n",
        "\n",
        "    for idx, row in intermediate_df.iterrows():\n",
        "        set_number = row[\"set_number\"]\n",
        "        feature_set = eval(row[\"features\"])\n",
        "        if pd.isnull(row[\"best_eps\"]) or pd.isnull(row[\"best_min_samples\"]):\n",
        "            continue\n",
        "\n",
        "        top10_eps_list = eval(row[\"top10_eps\"])\n",
        "        top10_min_samples_list = eval(row[\"top10_min_samples\"])\n",
        "\n",
        "        eps_min, eps_max = min(top10_eps_list), max(top10_eps_list)\n",
        "        eps_grid_fine = np.arange(eps_min, eps_max + 0.1, 0.1)\n",
        "\n",
        "        ms_min, ms_max = min(top10_min_samples_list), max(top10_min_samples_list)\n",
        "        min_samples_grid_fine = list(range(int(ms_min), int(ms_max) + 1))\n",
        "\n",
        "        missing_features = [feat for feat in feature_set if feat not in data.columns]\n",
        "        if missing_features:\n",
        "            continue\n",
        "\n",
        "        df_subset = data[feature_set]\n",
        "        df_subset = pd.DataFrame(StandardScaler().fit_transform(df_subset), columns=df_subset.columns)\n",
        "\n",
        "        score_list = []\n",
        "        for eps in eps_grid_fine:\n",
        "            for min_samples in min_samples_grid_fine:\n",
        "                try:\n",
        "                    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "                    labels = dbscan.fit_predict(df_subset)\n",
        "                    if len(set(labels)) > 1 and any(label != -1 for label in labels):\n",
        "                        score = silhouette_score(df_subset, labels)\n",
        "                        score_list.append((score, eps, min_samples))\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        if score_list:\n",
        "            score_list.sort(key=lambda x: x[0], reverse=True)\n",
        "            best_score, best_eps, best_min_samples = score_list[0]\n",
        "            final_results.append({\n",
        "                \"set_number\": set_number,\n",
        "                \"features\": feature_set,\n",
        "                \"best_eps\": best_eps,\n",
        "                \"best_min_samples\": best_min_samples,\n",
        "                \"best_silhouette_score\": best_score\n",
        "            })\n",
        "            print(f\"Fine tuning: Set {set_number} processed. Best: (eps: {best_eps}, min_samples: {best_min_samples}), Score: {best_score:.4f}\")\n",
        "        else:\n",
        "            final_results.append({\n",
        "                \"set_number\": set_number,\n",
        "                \"features\": feature_set,\n",
        "                \"best_eps\": None,\n",
        "                \"best_min_samples\": None,\n",
        "                \"best_silhouette_score\": None\n",
        "            })\n",
        "            print(f\"Fine tuning: Set {set_number} processed. No valid clustering found.\")\n",
        "\n",
        "    final_df = pd.DataFrame(final_results)\n",
        "    output_filename = expected_filename.replace(\"Intermediate_Top10\", \"Best_Fine_Params\")\n",
        "    final_df.to_csv(output_filename, index=False)\n",
        "    print(f\"\\nFine tuning for '{expected_filename}' complete. Final best parameters saved to '{output_filename}'.\")\n",
        "\n",
        "\n",
        "    files.download(output_filename)                                               # Download the CSV file"
      ]
    }
  ]
}